#!/bin/bash
# TODO document

set -o errexit -o nounset -o pipefail

export PGHOST
export PGUSER

readonly ExecAbsPath=$(readlink --canonicalize "$0")
readonly ExecName=$(basename "$ExecAbsPath")


main()
{
  local opts
  if ! opts=$(getopt --name "$ExecName" --longoptions host:,user: --options H:U: -- "$@")
  then
    printf 'failed to parse command line\n' >&2
    return 1
  fi

  eval set -- "$opts"

  while true
  do
    case "$1" in
      -H|--host)
        PGHOST="$2"
        shift 2
        ;;
      -U|--user)
        PGUSER="$2"
        shift 2
        ;;
      --)
        shift
        break
        ;;
      *)
        printf 'Unknown option %s\n' "$1" >&2
        return 1
        ;;
    esac
  done


  make_report
}


make_report()
{
  local msgs=tr-msg-entries
  if ! [[ -e "$msgs" ]]
  then
    track_call filter_msgs > "$msgs".tmp
    mv "$msgs".tmp "$msgs"
  fi

  local addModMsgs=tr-add-mod.json
  if ! [[ -e "$addModMsgs" ]]
  then
    track_call extract_addmod_msgs < "$msgs" | compact_addmod_msgs > "$addModMsgs".tmp
    mv "$addModMsgs".tmp "$addModMsgs"
  fi

  local openMsgs=tr-opens.csv
  if ! [[ -e "$openMsgs" ]]
  then
    track_call extract_open_msgs < "$msgs" | csv_open_msgs > "$openMsgs".tmp
    mv "$openMsgs".tmp "$openMsgs"
  fi

  local sizeMap=tr-size-map.csv
  if ! [[ -e "$sizeMap" ]]
  then
    track_call csv_entity_size_map "$(date '+%Y-%m-%d %H:%M:%S')" < "$addModMsgs" > "$sizeMap".tmp
    mv "$sizeMap".tmp "$sizeMap"
  fi

  local uploads=tr-uploads.csv
  if ! [[ -e "$uploads" ]]
  then
    track_call mk_uploads < "$addModMsgs" > "$uploads".tmp
    mv "$uploads".tmp "$uploads"
  fi

  local downloads=tr-downloads.csv
  if ! [[ -e "$downloads" ]]
  then
    track_call mk_downloads "$sizeMap" "$openMsgs" > "$downloads".tmp
    mv "$downloads".tmp "$downloads"
  fi

  local report=tr-report.csv
  if ! [[ -e "$report" ]]
  then
    paste --delimiters=, "$uploads" "$downloads" > "$report".tmp
    mv "$report".tmp "$report"
  fi

  cat "$report"
}


track_call()
{
  local func="$1"
  local cmd="$*"

  disp_begin_func "$func"
  eval "$cmd"
  disp_end_func "$func"
}


extract_addmod_msgs()
{
  awk --file - <(cat) \
<<'EOF'
  /"data-object\.(add|mod)"/ {
    timestamp = $1 "." $2;

    # Remove through message type, two blanks, and the leading quote
    match($0, /"data-object\.(add|mod)"/);
    offset = RSTART + RLENGTH + 3;
    msg = gensub(/\\("|')/, "\\1", "g", substr($0, offset));

    msg = substr(msg, 1, length(msg) - 1);  # remove trailing quote
    msg = gensub(/\r/, "\\r", "g", msg);    # escape carriage returns

    # Add timestamp to start of message and record separator before
    print "\x1e{\"timestamp\":\"" timestamp "\"," substr(msg, 2);
  }
EOF
}


extract_open_msgs()
{
  awk --file - <(cat) \
<<'EOF'
  /"data-object\.open"/ {
    # Remove through "data-object.open"m two blanks, and the leading quote
    match($0, /"data-object\.open"/);
    offset = RSTART + RLENGTH + 3;
    msg = gensub(/\\("|')/, "\\1", "g", substr($0, offset));

    # remove trailing quote
    msg = substr(msg, 1, length(msg) - 1);

    # escape carriage returns and prefix with record sep
    printf "\x1e%s\n", gensub(/\r/, "\\r", "g", msg);
  }
EOF
}


filter_msgs()
{
  awk --file - <(cat) \
<<'EOF'
  $4 == "NOTICE:" && $5 == "execCmd:cmd/amqptopicsend.py" {
    msg = gensub($3 " " $4 " ", "", 1, $0);

    # Remove potential trailing garabage
    msg = gensub(/[^\r]\\n.*/, "", 1, msg);

    # switch to unicode escapes
    print gensub(/\\x/, "\\u00", "g", msg);
  }
EOF
}


compact_addmod_msgs()
{
  jq \
    --compact-output --seq \
    --from-file <(cat \
<<'JQ'
  if (.timestamp | not) or (.entity | not) or (.size | not) then
    empty
  else
    { entity: .entity, timestamp: (.timestamp | split(".") | join(" ")),  size: .size }
  end
JQ
      )
}


csv_open_msgs()
{
  jq \
    --raw-output \
    --from-file <(cat \
<<'JQ'
  if (.timestamp | not) or (.entity | not) then
    empty
  else
    [ .entity, (.timestamp | split(".") | join(" ")) ]
  end |
  @csv
JQ
      )
}


csv_entity_size_map()
{
  local lastStopTs="$1"

  jq \
    --raw-output --slurp \
    --arg LAST_STOP_TS "$lastStopTs" \
    --from-file <(cat \
<<'JQ'
  # removes all of the leading objects that have a size of s from an array
  def ltrim_size(s):
    def trim_rec: if .[0].size != s then . else (.[1:] | trim_rec) end;
    if (length == 0) then [] else trim_rec end;

  # removes all objects that have the same size as the previous object in
  # an array
  def del_seq_sizes:
    def emit_keepers:
      if (length == 0) then
        empty
      else
        (first as $f |
         ($f,
          (.[1:] | ltrim_size($f.size) | emit_keepers)))
      end;
    [ emit_keepers ];

  # Transforms size entry to to intervaled size entry
  def to_interval(stop_ts):
    { obj: .entity, start_ts: .timestamp, stop_ts: stop_ts, size: .size };

  # Converts a size map to an intervaled size map
  def intervals:
    def emit_intervals(first_stop_ts):
      if (length == 0) then
        empty
      else
        ((first | to_interval(first_stop_ts)) as $f |
         ($f,
          (.[1:] | emit_intervals($f.start_ts))))
      end;
    reverse | [ emit_intervals($LAST_STOP_TS) ] | reverse;

  group_by(.entity) |
  map(sort_by(.timestamp) | del_seq_sizes | intervals) |
  flatten |
  .[] |
  [ .obj, .start_ts, .stop_ts, .size ] |
  @csv
JQ
      )
}


mk_uploads()
{
  jq \
    --raw-output --slurp \
    --from-file <(cat \
<<'JQ'
  [ .[] | if (.size | not) then empty else .size end ] |
  [ (. | length | tostring), (. | add | tostring) ] |
  "Upload Count,Upload Volume(B)\n" + join(",")
JQ
      )
}


mk_downloads()
{
  local sizeMapFile="$1"
  local downloadsFile="$2"

  printf 'Download Count,Download Volume(B)\n'
  summarize_downloads "$sizeMapFile" "$downloadsFile" \
    | tee >(tail --lines 4 | head --lines 1) >(disp_dbms_prog) \
    > /dev/null
}


summarize_downloads()
{
  local sizeMapFile="$1"
  local downloadsFile="$2"

  psql ICAT \
<<SQL
\\timing on
BEGIN;

\\echo 'Importing size mappings'
CREATE TEMPORARY TABLE size_map(
    data_uuid CHAR(37),
    start_time TIMESTAMP,
    stop_time TIMESTAMP,
    size BIGINT)
  ON COMMIT DROP;

COPY size_map FROM STDIN WITH (FORMAT CSV);
$(cat "$sizeMapFile")
\\.

CREATE INDEX idx_size_map_data_uuid_time ON size_map(data_uuid, start_time, stop_time);


\\echo 'Importing download events'
CREATE TEMPORARY TABLE downloads(data_uuid CHAR(37), time TIMESTAMP) ON COMMIT DROP;

COPY downloads FROM STDIN WITH (FORMAT CSV);
$(cat "$downloadsFile")
\\.

CREATE INDEX idx_downloads_data_all ON downloads(data_uuid, time);


\\echo 'Resolving download sizes using size mappings'
CREATE TEMPORARY TABLE sized_downloads(data_uuid, count, size) ON COMMIT DROP AS
SELECT d.data_uuid, COUNT(*), s.size
FROM downloads AS d
  LEFT JOIN size_map AS s
    ON s.data_uuid = d.data_uuid AND s.start_time <= d.time AND d.time < s.stop_time
GROUP BY d.data_uuid, s.size;

CREATE INDEX idx_sized_downloads_uuid ON sized_downloads(data_uuid);
CREATE INDEX idx_sized_downloads_all ON sized_downloads(data_uuid, count, size);


\\echo 'Resolving remaining download sizes using ICAT'
CREATE TEMPORARY TABLE resolved_downloads(data_uuid, count, size) ON COMMIT DROP AS
SELECT d.data_uuid, d.count, COALESCE(d.size, AVG(dm.data_size), 0)
FROM sized_downloads AS d
  LEFT JOIN r_meta_main AS mm
    ON mm.meta_attr_name = 'ipc_UUID' AND mm.meta_attr_value = d.data_uuid
  LEFT JOIN r_objt_metamap AS om ON om.meta_id = mm.meta_id
  LEFT JOIN r_data_main AS dm ON dm.data_id = om.object_id
GROUP BY d.data_uuid, d.count, d.size;


\\echo 'Exporting summary'
COPY (SELECT SUM(count), CAST(SUM(count * size) AS BIGINT) FROM resolved_downloads)
TO STDOUT
WITH (FORMAT CSV);


ROLLBACK;
SQL
}


disp_begin_func()
{
  local func="$1"

  printf '\e[32m%s: \e[1mbegin\e[0m' "$func" >&3
}


disp_end_func()
{
  local func="$1"

  printf '\033[1K\r\e[32m%s: \e[1mdone\e[0m\n' "$func" >&3
}


disp_dbms_prog()
{
  printf '\n' >&3

  while IFS= read -r
  do
    printf '  \e[32m%s\e[0m\n' "$REPLY" >&3
  done
}


disp_error()
{
  while IFS= read -r
  do
    if [[ "$(get_cursor_col)" -gt 0 ]]
    then
      printf '\n'
    fi

    printf '\e[31m%s\e[0m\n' "$REPLY"
  done >&2
}


get_cursor_col()
{
  # based on a script from http://invisible-island.net/xterm/xterm.faq.html
  exec < /dev/tty

  local oldStty
  oldStty=$(stty -g)
  stty raw -echo min 0

  local pos
  tput u7 > /dev/tty    # when TERM=xterm (and relatives)
  IFS=';' read -r -d R -a pos

  stty "$oldStty"

  # change from one-based to zero based so they work with: tput cup $row $col
  printf '%s' "$((pos[1] - 1))"
}


(main "$@" 3>&4 2>&1 1>&4 | disp_error) 4>&1
